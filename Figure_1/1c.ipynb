{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install imageio opencv-python alphashape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import geopandas as gpd\n",
    "import imageio as io\n",
    "import shapely.affinity as sa\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things that we may want to overlay:\n",
    "##### Transcripts, Aligned IF, Xenium DAPI, H and E, cell segmentation, transcripts/cell masks colored by cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"day8_SI_r2\"\n",
    "whole_adata = sc.read(\"../data/adata/timecourse.h5ad\")\n",
    "finalized_adata = whole_adata[whole_adata.obs.batch == experiment_name]\n",
    "\n",
    "# the following has the transcripts saved. It is a temporary adata along the processing pipeline\n",
    "path_to_adata_with_transcripts = \"../data/adata/day8_r2_with_transcripts.h5ad\"\n",
    "\n",
    "# all h and e and IF are generated and saved\n",
    "path_to_h_and_e = \"../data/images/day8_r2_h_and_e_alignment_gan.npy\"\n",
    "path_to_if = \"../data/images/day8_r2_IF_alignment.npy\"\n",
    "\n",
    "xenium_output_path = \"../data/xenium_output/day8_r2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_image(path: str):\n",
    "    file = os.path.join(path, \"morphology_mip.ome.tif\")\n",
    "    img = io.imread(file)\n",
    "    return img\n",
    "\n",
    "\n",
    "# load in H&E, DAPI, and IF images\n",
    "xenium_dapi = import_image(xenium_output_path)\n",
    "\n",
    "try:\n",
    "    IF_image = np.load(path_to_if)\n",
    "except:\n",
    "    print(\"No IF for this experiment\")\n",
    "    IF_image = xenium_dapi\n",
    "\n",
    "try:\n",
    "    h_an_e = np.load(path_to_h_and_e)\n",
    "except:\n",
    "    print(\"No H&E for this experiment\")\n",
    "    h_an_e = xenium_dapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the adata holding the transcripts\n",
    "transcripts = sc.read(path_to_adata_with_transcripts)\n",
    "points = transcripts.uns[\"points\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##save the different parts of the transcripts df for fast indexing\n",
    "points_x = points.x.values\n",
    "points_y = points.y.values\n",
    "points_z = points.z.values\n",
    "points_gene = points.gene.values\n",
    "points_cell = points.cell.values\n",
    "points_split_cell = points.split_cell.values\n",
    "points[\"split_cell\"] = points[\"split_cell\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pixel_size(path: str) -> float:\n",
    "    file = open(os.path.join(path, \"experiment.xenium\"))\n",
    "    experiment = json.load(file)\n",
    "    pixel_size = experiment[\"pixel_size\"]\n",
    "    return pixel_size\n",
    "\n",
    "\n",
    "# transform the transcript coordinates from microns to pixels\n",
    "pixel_size = get_pixel_size(xenium_output_path)\n",
    "transformed_x = points_x * (1 / pixel_size)\n",
    "transformed_y = points_y * (1 / pixel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscaling the dapi overview by 50x (you can change this with no side effects other than runtime in the next cell)\n",
    "\n",
    "down_factor = 50\n",
    "\n",
    "new_width = int(xenium_dapi.shape[1] / down_factor)\n",
    "new_height = int(xenium_dapi.shape[0] / down_factor)\n",
    "\n",
    "thumbnail = cv2.resize(xenium_dapi, (new_width, new_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_y = 555\n",
    "max_y = 600\n",
    "\n",
    "min_x = 368\n",
    "max_x = 379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the transcripts falling in the box you created\n",
    "\n",
    "min_x = min_x * down_factor\n",
    "min_y = min_y * down_factor\n",
    "max_x = max_x * down_factor\n",
    "max_y = max_y * down_factor\n",
    "\n",
    "\n",
    "subsetted_indices = np.where(\n",
    "    (transformed_x > min_y)\n",
    "    & (transformed_x < max_y)\n",
    "    & (transformed_y > min_x)\n",
    "    & (transformed_y < max_x)\n",
    ")[0]\n",
    "\n",
    "transcripts_df = pd.DataFrame(\n",
    "    zip(\n",
    "        transformed_x[subsetted_indices],\n",
    "        transformed_y[subsetted_indices],\n",
    "        points_gene[subsetted_indices],\n",
    "        points_split_cell[subsetted_indices],\n",
    "    ),\n",
    "    index=points_cell[subsetted_indices],\n",
    "    columns=[\"x\", \"y\", \"gene\", \"split_cell\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = {\n",
    "    \"B-Cell\": \"LP\",\n",
    "    \"Cd4_T-Cell\": \"LP\",\n",
    "    \"Cd8_T-Cell_P14\": \"LP\",\n",
    "    \"Cd8_T-Cell_aa+\": \"Epithelial\",\n",
    "    \"Cd8_T-Cell_ab+\": \"Epithelial\",\n",
    "    \"Complement_Fibroblast\": \"Muscularis\",\n",
    "    \"DC2\": \"LP\",\n",
    "    \"Early_Enterocyte\": \"Epithelial\",\n",
    "    \"Enterocyte_1\": \"Epithelial\",\n",
    "    \"Enterocyte_2\": \"Epithelial\",\n",
    "    \"Enterocyte_3\": \"Epithelial\",\n",
    "    \"Enteroendocrine\": \"Epithelial\",\n",
    "    \"Eosinophil\": \"LP\",\n",
    "    \"Fibroblast\": \"Muscularis\",\n",
    "    \"Fibroblast_Ncam1\": \"Muscularis\",\n",
    "    \"Fibroblast_Pdgfra+\": \"Muscularis\",\n",
    "    \"Fibroblast_Pdgfrb+ \": \"Muscularis\",\n",
    "    \"Goblet\": \"Epithelial\",\n",
    "    \"ILC\": \"LP\",\n",
    "    \"ISC\": \"Crypt\",\n",
    "    \"Lymphatic\": \"Muscularis\",\n",
    "    \"MAIT\": \"LP\",\n",
    "    \"Macrophage\": \"LP\",\n",
    "    \"MegakaryocytePlatelet\": \"None\",\n",
    "    \"Monocyte\": \"None\",\n",
    "    \"Myofibroblast\": \"Muscularis\",\n",
    "    \"NK-Cell\": \"LP\",\n",
    "    \"Neuron\": \"Muscularis\",\n",
    "    \"Paneth\": \"Crypt\",\n",
    "    \"Resting Fibroblast\": \"Crypt\",\n",
    "    \"T-Cell\": \"Epithelial\",\n",
    "    \"T-Cell gd\": \"Epithelial\",\n",
    "    \"Transit_Amplifying\": \"Crypt\",\n",
    "    \"Tuft\": \"Epithelial\",\n",
    "    \"Vascular Endothelial\": \"Muscularis\",\n",
    "    \"cDC1\": \"LP\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regions = []\n",
    "for i in finalized_adata.obs[\"Subtype\"]:\n",
    "    all_regions.append(region_dict.get(i))\n",
    "\n",
    "finalized_adata.obs[\"Region\"] = pd.Categorical(all_regions)\n",
    "\n",
    "finalized_adata.uns[\"Region_colors\"] = [\n",
    "    \"#FFB6C1\",\n",
    "    \"#ADD8E6\",\n",
    "    \"#FDFA72\",\n",
    "    \"#90EE90\",\n",
    "    \"#D3D3D3\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Money shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_down = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thumbnail = cv2.resize(\n",
    "    h_an_e, (np.shape(h_an_e)[0] // plot_down, np.shape(h_an_e)[1] // plot_down)\n",
    ")\n",
    "# Define the RGB value for black\n",
    "black_color = [0, 0, 0]\n",
    "\n",
    "# Create a mask for black pixels\n",
    "black_pixels = np.all(thumbnail[:, :, :3] == black_color, axis=-1)\n",
    "\n",
    "# Replace black pixels with white\n",
    "thumbnail[black_pixels] = [255, 255, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax0 = plt.gca()\n",
    "# Assuming 'thumbnail' is your image data\n",
    "ax0.imshow(thumbnail)\n",
    "ax0.set_xlim(300, np.shape(thumbnail)[1])\n",
    "ax0.set_ylim(np.shape(thumbnail)[0], 400)\n",
    "\n",
    "# Add a black rectangle\n",
    "rectangle = Rectangle(\n",
    "    (min_y // plot_down, min_x // plot_down),\n",
    "    max_y // plot_down - min_y // plot_down,\n",
    "    max_x // plot_down - min_x // plot_down,\n",
    "    linewidth=2,\n",
    "    edgecolor=\"black\",\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "ax0.add_patch(rectangle)\n",
    "ax0.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_min_y = 1440\n",
    "second_max_y = 1600\n",
    "\n",
    "second_min_x = 150\n",
    "second_max_x = 450\n",
    "\n",
    "side1 = min_y + second_min_y\n",
    "side2 = max_y - (max_y - (min_y + second_max_y))\n",
    "side3 = second_min_x + min_x\n",
    "side4 = max_x - (max_x - (second_max_x + min_x))\n",
    "\n",
    "subsetted_indices_second = np.where(\n",
    "    (transformed_x > side1)\n",
    "    & (transformed_x < side2)\n",
    "    & (transformed_y > side3)\n",
    "    & (transformed_y < side4)\n",
    ")[0]\n",
    "\n",
    "transcripts_df_second = pd.DataFrame(\n",
    "    zip(\n",
    "        transformed_x[subsetted_indices_second],\n",
    "        transformed_y[subsetted_indices_second],\n",
    "        points_gene[subsetted_indices_second],\n",
    "        points_split_cell[subsetted_indices_second],\n",
    "    ),\n",
    "    index=points_cell[subsetted_indices_second],\n",
    "    columns=[\"x\", \"y\", \"gene\", \"split_cell\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4), dpi=300)\n",
    "ax3 = plt.gca()\n",
    "# Assuming 'thumbnail' is your image data\n",
    "img_cropped = h_an_e[min_x:max_x, min_y:max_y]\n",
    "ax3.imshow(img_cropped)\n",
    "\n",
    "# Add a black rectangle\n",
    "rectangle = Rectangle(\n",
    "    (second_min_y, second_min_x),\n",
    "    second_max_y - second_min_y,\n",
    "    second_max_x - second_min_x,\n",
    "    linewidth=4,\n",
    "    edgecolor=\"black\",\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "ax3.add_patch(rectangle)\n",
    "ax3.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4), dpi=300)\n",
    "ax4 = plt.gca()\n",
    "if_channels = [2, 1]\n",
    "# Rest of the axes\n",
    "mapped_ims = []\n",
    "for g in range(len(if_channels)):\n",
    "    image = IF_image[min_x:max_x, min_y:max_y, if_channels[g]]\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "\n",
    "    normalized_image = (image - min_val) / (max_val - min_val)\n",
    "\n",
    "    # plt.hist(image)\n",
    "    # plt.show()\n",
    "\n",
    "    if if_channels[g] == 2:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (30, 30))\n",
    "        # Top Hat Transform\n",
    "        topHat = cv2.morphologyEx(normalized_image, cv2.MORPH_TOPHAT, kernel)\n",
    "        # Black Hat Transform\n",
    "        blackHat = cv2.morphologyEx(normalized_image, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "        normalized_image = normalized_image + topHat - blackHat\n",
    "\n",
    "        normalized_image = normalized_image * 2\n",
    "\n",
    "    mapped_ims.append(normalized_image)\n",
    "mapped_ims.append(\n",
    "    np.zeros(np.shape(IF_image[min_x:max_x, min_y:max_y, if_channels[g]]))\n",
    ")\n",
    "full_im = np.dstack(mapped_ims)\n",
    "ax4.imshow(full_im)\n",
    "# Add a black rectangle\n",
    "rectangle2 = Rectangle(\n",
    "    (second_min_y, second_min_x),\n",
    "    second_max_y - second_min_y,\n",
    "    second_max_x - second_min_x,\n",
    "    linewidth=4,\n",
    "    edgecolor=\"white\",\n",
    "    facecolor=\"none\",\n",
    ")\n",
    "ax4.add_patch(rectangle2)\n",
    "ax4.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alphashape\n",
    "\n",
    "\n",
    "def make_alphashape(points: pd.DataFrame, alpha: float):\n",
    "    points = np.array(points)\n",
    "    shape = alphashape.alphashape(points, alpha=alpha)\n",
    "    return shape\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 4), dpi=300)\n",
    "ax1 = plt.gca()\n",
    "\n",
    "segmentation_face_color = \"leiden\"\n",
    "inside_alpha = 0.34\n",
    "outside_alpha = 0.34\n",
    "celltypes = []\n",
    "ids = np.array([i.split(\"_\")[-1] for i in finalized_adata.obs.index.values]).astype(int)\n",
    "id_df = pd.DataFrame(\n",
    "    zip(ids, finalized_adata.obs[segmentation_face_color].values),\n",
    "    columns=[\"id\", segmentation_face_color],\n",
    ")\n",
    "transcripts_with_obs = transcripts_df.merge(\n",
    "    id_df, left_on=\"split_cell\", right_on=\"id\", how=\"left\"\n",
    ")\n",
    "transcripts_with_obs = transcripts_with_obs.dropna(axis=0)\n",
    "\n",
    "\n",
    "print(\"Making Shapes\")\n",
    "gby = transcripts_with_obs[\n",
    "    (transcripts_with_obs.split_cell != 0) & (transcripts_with_obs.split_cell != -1)\n",
    "].groupby(\"split_cell\")\n",
    "\n",
    "\n",
    "shapes = []\n",
    "for group in tqdm(gby):\n",
    "    shapes.append(make_alphashape(group[1][[\"x\", \"y\"]].values, alpha=0.05))\n",
    "    ctype = group[1][segmentation_face_color].values[0]\n",
    "    cell_location = np.where(\n",
    "        finalized_adata.obs[segmentation_face_color].cat.categories == ctype\n",
    "    )[0]\n",
    "    try:\n",
    "        celltypes.append(\n",
    "            finalized_adata.uns[f\"{segmentation_face_color}_colors\"][cell_location][0]\n",
    "        )\n",
    "    except:\n",
    "        celltypes.append(\n",
    "            finalized_adata.uns[f\"{segmentation_face_color}_colors\"][cell_location[0]]\n",
    "        )\n",
    "shapes = gpd.GeoSeries(shapes)\n",
    "colors = celltypes\n",
    "\n",
    "\n",
    "img_cropped = xenium_dapi[\n",
    "    min_x:max_x, min_y:max_y\n",
    "]  # [second_min_x:second_max_x, second_min_y:second_max_y]\n",
    "ax1.imshow(img_cropped, vmax=np.percentile(img_cropped, 99.9), cmap=\"Greys_r\")\n",
    "\n",
    "# Create an empty GeoDataFrame to store adjusted polygons\n",
    "adjusted_shapes = []\n",
    "\n",
    "# Iterate through the shapes DataFrame and adjust each polygon\n",
    "for original_polygon in shapes:\n",
    "    scaled_polygon = sa.translate(original_polygon, -min_y, -min_x)\n",
    "    adjusted_shapes.append(scaled_polygon)\n",
    "\n",
    "adjusted_shapes = gpd.GeoSeries(adjusted_shapes)\n",
    "\n",
    "for geometry, color in zip(adjusted_shapes, colors):\n",
    "    if geometry.geom_type == \"Polygon\":\n",
    "        patch = plt.Polygon(\n",
    "            list(zip(*geometry.exterior.xy)),\n",
    "            facecolor=color,\n",
    "            edgecolor=\"none\",\n",
    "            alpha=inside_alpha,\n",
    "            zorder=1,\n",
    "        )\n",
    "        ax1.add_patch(patch)\n",
    "    elif geometry.geom_type == \"MultiPolygon\":\n",
    "        for poly in geometry:\n",
    "            patch = plt.Polygon(\n",
    "                list(zip(*poly.exterior.xy)),\n",
    "                facecolor=color,\n",
    "                edgecolor=\"none\",\n",
    "                alpha=inside_alpha,\n",
    "                zorder=1,\n",
    "            )\n",
    "            ax1.add_patch(patch)\n",
    "\n",
    "# Plot polygon edges with edgecolor based on data values\n",
    "for geometry, color in zip(adjusted_shapes, colors):\n",
    "    if geometry.geom_type == \"Polygon\":\n",
    "        ax1.plot(*geometry.exterior.xy, color=color, alpha=outside_alpha)\n",
    "    elif geometry.geom_type == \"MultiPolygon\":\n",
    "        for poly in geometry:\n",
    "            ax1.plot(*poly.exterior.xy, color=color, alpha=outside_alpha)\n",
    "\n",
    "\n",
    "rectangle2 = Rectangle(\n",
    "    (second_min_y, second_min_x),\n",
    "    second_max_y - second_min_y,\n",
    "    second_max_x - second_min_x,\n",
    "    linewidth=4,\n",
    "    edgecolor=\"white\",\n",
    "    facecolor=\"none\",\n",
    "    zorder=2,\n",
    ")\n",
    "ax1.add_patch(rectangle2)\n",
    "ax1.set_xlim(0, max_y - min_y)\n",
    "ax1.set_ylim(0, max_x - min_x)\n",
    "ax1.invert_yaxis()\n",
    "# ax1.axis('equal')\n",
    "ax1.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10), dpi=300)\n",
    "ax1 = plt.gca()\n",
    "\n",
    "segmentation_face_color = \"leiden\"\n",
    "inside_alpha = 0.34\n",
    "outside_alpha = 0.8\n",
    "celltypes = []\n",
    "ids = np.array([i.split(\"_\")[-1] for i in finalized_adata.obs.index.values]).astype(int)\n",
    "id_df = pd.DataFrame(\n",
    "    zip(ids, finalized_adata.obs[segmentation_face_color].values),\n",
    "    columns=[\"id\", segmentation_face_color],\n",
    ")\n",
    "transcripts_with_obs = transcripts_df_second.merge(\n",
    "    id_df, left_on=\"split_cell\", right_on=\"id\", how=\"left\"\n",
    ")\n",
    "transcripts_with_obs = transcripts_with_obs.dropna(axis=0)\n",
    "\n",
    "\n",
    "print(\"Making Shapes\")\n",
    "gby = transcripts_with_obs[\n",
    "    (transcripts_with_obs.split_cell != 0) & (transcripts_with_obs.split_cell != -1)\n",
    "].groupby(\"split_cell\")\n",
    "\n",
    "\n",
    "shapes = []\n",
    "for group in tqdm(gby):\n",
    "    shapes.append(make_alphashape(group[1][[\"x\", \"y\"]].values, alpha=0.05))\n",
    "    ctype = group[1][segmentation_face_color].values[0]\n",
    "    cell_location = np.where(\n",
    "        finalized_adata.obs[segmentation_face_color].cat.categories == ctype\n",
    "    )[0]\n",
    "    try:\n",
    "        celltypes.append(\n",
    "            finalized_adata.uns[f\"{segmentation_face_color}_colors\"][cell_location][0]\n",
    "        )\n",
    "    except:\n",
    "        celltypes.append(\n",
    "            finalized_adata.uns[f\"{segmentation_face_color}_colors\"][cell_location[0]]\n",
    "        )\n",
    "shapes = gpd.GeoSeries(shapes)\n",
    "colors = [\"#D3D3D3\" for s in range(len(shapes))]\n",
    "\n",
    "\n",
    "img_cropped = xenium_dapi[min_x:max_x, min_y:max_y][\n",
    "    second_min_x:second_max_x, second_min_y:second_max_y\n",
    "]\n",
    "ax1.imshow(\n",
    "    img_cropped,\n",
    "    vmax=np.percentile(img_cropped, 99.9),\n",
    "    vmin=np.percentile(img_cropped, 30),\n",
    "    cmap=\"Greys_r\",\n",
    ")\n",
    "\n",
    "# Create an empty GeoDataFrame to store adjusted polygons\n",
    "adjusted_shapes = []\n",
    "\n",
    "# Iterate through the shapes DataFrame and adjust each polygon\n",
    "for original_polygon in shapes:\n",
    "    scaled_polygon = sa.translate(\n",
    "        original_polygon, -min_y - second_min_y, -min_x - second_min_x\n",
    "    )\n",
    "    adjusted_shapes.append(scaled_polygon)\n",
    "\n",
    "adjusted_shapes = gpd.GeoSeries(adjusted_shapes)\n",
    "\n",
    "for geometry, color in zip(adjusted_shapes, colors):\n",
    "    if geometry.geom_type == \"Polygon\":\n",
    "        patch = plt.Polygon(\n",
    "            list(zip(*geometry.exterior.xy)),\n",
    "            facecolor=color,\n",
    "            edgecolor=\"none\",\n",
    "            alpha=inside_alpha,\n",
    "            zorder=1,\n",
    "        )\n",
    "        ax1.add_patch(patch)\n",
    "    elif geometry.geom_type == \"MultiPolygon\":\n",
    "        for poly in geometry:\n",
    "            patch = plt.Polygon(\n",
    "                list(zip(*poly.exterior.xy)),\n",
    "                facecolor=color,\n",
    "                edgecolor=\"none\",\n",
    "                alpha=inside_alpha,\n",
    "                zorder=1,\n",
    "            )\n",
    "            ax1.add_patch(patch)\n",
    "\n",
    "# Plot polygon edges with edgecolor based on data values\n",
    "for geometry, color in zip(adjusted_shapes, colors):\n",
    "    if geometry.geom_type == \"Polygon\":\n",
    "        ax1.plot(*geometry.exterior.xy, color=color, linewidth=4, alpha=outside_alpha)\n",
    "    elif geometry.geom_type == \"MultiPolygon\":\n",
    "        for poly in geometry:\n",
    "            ax1.plot(*poly.exterior.xy, color=color, linewidth=4, alpha=outside_alpha)\n",
    "\n",
    "transcripts_genes_only = transcripts_df_second\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# Function to generate a random color in RGB format\n",
    "def random_color():\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(\n",
    "        random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)\n",
    "    )\n",
    "\n",
    "\n",
    "transcript_colors = [random_color() for _ in range(500)]\n",
    "pt_size = 1.2\n",
    "gene_subset = finalized_adata.var.index.values\n",
    "col_ct = 0\n",
    "for i in gene_subset:\n",
    "    transcripts_genes_only_current = transcripts_genes_only[\n",
    "        transcripts_genes_only[\"gene\"] == i\n",
    "    ]\n",
    "    for x, y in zip(\n",
    "        transcripts_genes_only_current.x.values, transcripts_genes_only_current.y.values\n",
    "    ):\n",
    "        circle = patches.Circle(\n",
    "            (x - (min_y + second_min_y), y - (min_x + second_min_x)),\n",
    "            radius=pt_size,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.01,\n",
    "            facecolor=transcript_colors[col_ct],\n",
    "            alpha=1,\n",
    "            zorder=2,\n",
    "        )\n",
    "        ax1.add_patch(circle)\n",
    "    col_ct += 1\n",
    "\n",
    "col_ct = 0\n",
    "for i in gene_subset:\n",
    "    plt.scatter([], [], c=transcript_colors[col_ct], label=i)\n",
    "    col_ct += 1\n",
    "\n",
    "ax1.invert_yaxis()\n",
    "ax1.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p14s = []\n",
    "for i in finalized_adata.obs[\"Subtype\"].values:\n",
    "    if i == \"Cd8_T-Cell_P14\":\n",
    "        p14s.append(1)\n",
    "    else:\n",
    "        p14s.append(0)\n",
    "finalized_adata.obs[\"p14\"] = p14s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 10), dpi=300)\n",
    "ax1 = plt.gca()\n",
    "\n",
    "segmentation_face_color = \"p14\"\n",
    "inside_alpha = 0.2\n",
    "outside_alpha = 0.8\n",
    "celltypes = []\n",
    "ids = np.array([i.split(\"_\")[-1] for i in finalized_adata.obs.index.values]).astype(int)\n",
    "id_df = pd.DataFrame(\n",
    "    zip(ids, finalized_adata.obs[segmentation_face_color].values),\n",
    "    columns=[\"id\", segmentation_face_color],\n",
    ")\n",
    "transcripts_with_obs = transcripts_df_second.merge(\n",
    "    id_df, left_on=\"split_cell\", right_on=\"id\", how=\"left\"\n",
    ")\n",
    "transcripts_with_obs = transcripts_with_obs.dropna(axis=0)\n",
    "\n",
    "\n",
    "print(\"Making Shapes\")\n",
    "gby = transcripts_with_obs[\n",
    "    (transcripts_with_obs.split_cell != 0) & (transcripts_with_obs.split_cell != -1)\n",
    "].groupby(\"split_cell\")\n",
    "\n",
    "\n",
    "shapes = []\n",
    "colors = []\n",
    "for group in tqdm(gby):\n",
    "    shapes.append(make_alphashape(group[1][[\"x\", \"y\"]].values, alpha=0.05))\n",
    "    ctype = group[1][segmentation_face_color].values[0]\n",
    "    # if ctype == 1:\n",
    "    #     colors.append('#00FF00')\n",
    "    # else:\n",
    "    colors.append(\"#D3D3D3\")\n",
    "shapes = gpd.GeoSeries(shapes)\n",
    "\n",
    "if_channels = [2, 1]\n",
    "# Rest of the axes\n",
    "mapped_ims = []\n",
    "for g in range(len(if_channels)):\n",
    "    image = IF_image[min_x:max_x, min_y:max_y, if_channels[g]][\n",
    "        second_min_x:second_max_x, second_min_y:second_max_y\n",
    "    ]\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "\n",
    "    normalized_image = (image - min_val) / (max_val - min_val)\n",
    "\n",
    "    if if_channels[g] == 2:\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (50, 50))\n",
    "        # Top Hat Transform\n",
    "        topHat = cv2.morphologyEx(normalized_image, cv2.MORPH_TOPHAT, kernel)\n",
    "        # Black Hat Transform\n",
    "        blackHat = cv2.morphologyEx(normalized_image, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "        normalized_image = normalized_image + topHat - blackHat\n",
    "\n",
    "        normalized_image = normalized_image**2\n",
    "\n",
    "    mapped_ims.append(normalized_image)\n",
    "mapped_ims.append(\n",
    "    np.zeros(\n",
    "        np.shape(\n",
    "            IF_image[min_x:max_x, min_y:max_y, if_channels[g]][\n",
    "                second_min_x:second_max_x, second_min_y:second_max_y\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "full_im = np.dstack(mapped_ims)\n",
    "\n",
    "img_cropped = full_im\n",
    "ax1.imshow(\n",
    "    img_cropped,\n",
    "    vmax=np.percentile(img_cropped, 99.9),\n",
    "    vmin=np.percentile(img_cropped, 30),\n",
    "    cmap=\"Greys_r\",\n",
    ")\n",
    "\n",
    "# Create an empty GeoDataFrame to store adjusted polygons\n",
    "adjusted_shapes = []\n",
    "\n",
    "# Iterate through the shapes DataFrame and adjust each polygon\n",
    "for original_polygon in shapes:\n",
    "    scaled_polygon = sa.translate(\n",
    "        original_polygon, -min_y - second_min_y, -min_x - second_min_x\n",
    "    )\n",
    "    adjusted_shapes.append(scaled_polygon)\n",
    "\n",
    "transcripts_genes_only = transcripts_df_second\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "# Function to generate a random color in RGB format\n",
    "def random_color():\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(\n",
    "        random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)\n",
    "    )\n",
    "\n",
    "\n",
    "xist = \"#00FFFF\"\n",
    "cd8a = \"#FEFDFD\"  # White\n",
    "cd8b1 = \"#a7a7a7\"  # Bright Red\n",
    "gzmb = \"#FF00FF\"\n",
    "\n",
    "transcript_colors = [cd8a, cd8b1, gzmb, xist]\n",
    "\n",
    "pt_size = 1.5\n",
    "gene_subset = [\"Cd8a\", \"Cd8b1\", \"Gzmb\", \"Xist\"]\n",
    "col_ct = 0\n",
    "for i in gene_subset:\n",
    "    transcripts_genes_only_current = transcripts_genes_only[\n",
    "        transcripts_genes_only[\"gene\"] == i\n",
    "    ]\n",
    "    for x, y in zip(\n",
    "        transcripts_genes_only_current.x.values, transcripts_genes_only_current.y.values\n",
    "    ):\n",
    "        circle = patches.Circle(\n",
    "            (x - (min_y + second_min_y), y - (min_x + second_min_x)),\n",
    "            radius=pt_size,\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.01,\n",
    "            facecolor=transcript_colors[col_ct],\n",
    "            alpha=1,\n",
    "            zorder=2,\n",
    "        )\n",
    "        ax1.add_patch(circle)\n",
    "    col_ct += 1\n",
    "\n",
    "col_ct = 0\n",
    "for i in gene_subset:\n",
    "    plt.scatter([], [], c=transcript_colors[col_ct], label=i)\n",
    "    col_ct += 1\n",
    "\n",
    "ax1.axis(\"off\")\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merscope_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
