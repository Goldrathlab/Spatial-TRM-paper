{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scanpy as sc\n",
    "import os\n",
    "from scipy.spatial import KDTree\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF\n",
    "from tqdm.notebook import tqdm\n",
    "from core_functions.neighborhood_decomposition import *\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Similarly to replicate 1 processing, we will use the Epithelial and Stromal classes defined by GeneFormer to perform a spatial decompostion on Epithelial and Stromal cells so that we have a feature set for crypt villus axis prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "##### Path to replicate datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = r\"/mnt/sata1/Analysis_Alex/timecourse_replicates/analysis/cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folders = glob.glob(\"/mnt/sata1/Analysis_Alex/timecourse_replicates/day*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = []\n",
    "for input_file in input_folders:\n",
    "    adatas.append(\n",
    "        sc.read(os.path.join(input_file, \"adatas\", \"08_full_celltypes_and_leiden.h5ad\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "##### Path to replicate 1 final dataset. We will be using the same reference dataset for morphology prediction as we used in the replicate 1 processing, in our case - Day 7 DMSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_path = r\"/mnt/sata1/Analysis_Alex/timecourse_final/analysis/cleaned/final_celltyped_and_axes.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only the reference data (the dataset with the best morphology that was treated as a reference for the first set of replicates)\n",
    "reference_adata = sc.read(reference_path)\n",
    "reference_adata = reference_adata[reference_adata.obs[\"batch\"] == \"day7_SI_DMSO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas.append(reference_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_adata = sc.concat(adatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "del adatas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Train Decomposition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "unchanging_type_keys = [\"Epithelial\", \"Stromal\"]\n",
    "combined_adata_no_immune = combined_adata[\n",
    "    combined_adata.obs[\"Class\"].isin(unchanging_type_keys)\n",
    "]\n",
    "unique_batches = np.unique(combined_adata_no_immune.obs.batch.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "nneighbors = 10\n",
    "dfs = []\n",
    "for input_file in unique_batches:\n",
    "    adata = combined_adata_no_immune[\n",
    "        combined_adata_no_immune.obs[\"batch\"] == input_file\n",
    "    ]\n",
    "    adata_arr = np.array(adata.X)\n",
    "    celltype_cluster = adata.obs.index.values\n",
    "    list_of_arrays = []\n",
    "    spatial_points = np.array(\n",
    "        [adata.obsm[\"X_spatial\"][:, 0], adata.obsm[\"X_spatial\"][:, 1]]\n",
    "    ).T\n",
    "    tree = KDTree(spatial_points)\n",
    "    for i_bac in tqdm(range(len(celltype_cluster))):\n",
    "        current_cell = celltype_cluster[i_bac]\n",
    "        distances, neighbors = tree.query(spatial_points[i_bac], k=nneighbors)\n",
    "        neighbors = np.array(list(neighbors))\n",
    "        gene_array = np.array(np.sum(adata_arr[neighbors, :], axis=0)).squeeze()\n",
    "        list_of_arrays.append(gene_array)\n",
    "\n",
    "    X = pd.DataFrame(np.array(list_of_arrays))\n",
    "    dfs.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "del combined_adata\n",
    "del combined_adata_no_immune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighborhoods = 15\n",
    "X = X_arr\n",
    "del X_arr\n",
    "f = len(X.columns)\n",
    "n = len(X.index.tolist())\n",
    "\n",
    "model = NMF(n_components=num_neighborhoods, random_state=0)\n",
    "W = model.fit_transform(X)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Apply decomposition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in input_folders:\n",
    "    adata = sc.read(\n",
    "        os.path.join(input_file, \"adatas\", \"08_full_celltypes_and_leiden.h5ad\")\n",
    "    )\n",
    "\n",
    "    superclusters = adata.obs[\"Class\"].values\n",
    "    celltype_cluster = adata.obs.index.values\n",
    "\n",
    "    base_dictionary = {}\n",
    "    for i in np.unique(celltype_cluster):\n",
    "        base_dictionary[i] = 0\n",
    "\n",
    "    nneighbors = 10\n",
    "    list_of_arrays = []\n",
    "    adata_epi = adata[adata.obs[\"Class\"].isin(unchanging_type_keys)]\n",
    "    spatial_points_epi = np.array(\n",
    "        [adata_epi.obsm[\"X_spatial\"][:, 0], adata_epi.obsm[\"X_spatial\"][:, 1]]\n",
    "    ).T\n",
    "    spatial_points = np.array(\n",
    "        [adata.obsm[\"X_spatial\"][:, 0], adata.obsm[\"X_spatial\"][:, 1]]\n",
    "    ).T\n",
    "    adata_epi_arr = np.array(adata_epi.X)\n",
    "\n",
    "    tree = KDTree(spatial_points_epi)\n",
    "    for i_bac in tqdm(range(len(celltype_cluster))):\n",
    "        current_cell = celltype_cluster[i_bac]\n",
    "        distances, neighbors = tree.query(spatial_points[i_bac], k=nneighbors)\n",
    "        neighbors = np.array(list(neighbors))\n",
    "        gene_array = np.array(np.sum(adata_epi_arr[neighbors, :], axis=0)).squeeze()\n",
    "        list_of_arrays.append(gene_array)\n",
    "\n",
    "    X = pd.DataFrame(np.array(list_of_arrays)).astype(H.dtype)\n",
    "    W = model.transform(X)\n",
    "\n",
    "    topics_frame = pd.DataFrame(W)\n",
    "\n",
    "    topics_frame.columns = [\n",
    "        \"Topic \" + str(i + 1) for i in range(len(topics_frame.columns))\n",
    "    ]\n",
    "    topics_frame.index = adata.obs.index.tolist()\n",
    "\n",
    "    def zscore(column):\n",
    "        return (column - column.mean()) / column.std()\n",
    "\n",
    "    # Apply the z-score function to each column in the dataframe\n",
    "    topics_frame = topics_frame.apply(zscore)\n",
    "    adata.obs = adata.obs.merge(topics_frame, left_index=True, right_index=True)\n",
    "    adata.obs[\"topic\"] = pd.Categorical(\n",
    "        (np.argmax(topics_frame.values, axis=1) + 1).astype(str)\n",
    "    )\n",
    "\n",
    "    sc.set_figure_params(dpi=300)\n",
    "    figure = sc.pl.embedding(\n",
    "        adata,\n",
    "        basis=\"spatial\",\n",
    "        color=\"topic\",\n",
    "        vmax=1,\n",
    "        cmap=\"Blues\",\n",
    "        title=\"Neighborhood\",\n",
    "        size=2,\n",
    "        show=False,\n",
    "        return_fig=True,\n",
    "    )\n",
    "    try:\n",
    "        os.mkdir(os.path.join(input_file, \"figures\", \"neighborhoods\"))\n",
    "    except:\n",
    "        print(\"Figures/neighborhoods already made.\")\n",
    "    figure.tight_layout()\n",
    "    plt.axis(\"equal\")\n",
    "    figure.savefig(\n",
    "        os.path.join(input_file, \"figures\", \"neighborhoods\", \"neighborhoods.png\")\n",
    "    )\n",
    "    plt.close()\n",
    "    adata.write(\n",
    "        os.path.join(input_file, \"adatas\", \"09_before_decomposition_model.h5ad\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Adding topic enrichment vectors to  the reference day 7 DMSO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "xenium_path = \"/mnt/sata1/Analysis_Alex/timecourse_final/day7_SI_DMSO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_prep = sc.read(\n",
    "    os.path.join(xenium_path, \"adatas\", \"07_axes_defined_reference.h5ad\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_prep.obs = reference_prep.obs.drop(\n",
    "    reference_prep.obs.columns[reference_prep.obs.columns.str.contains(\"Topic\")], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "superclusters = reference_prep.obs[\"Class\"].values\n",
    "celltype_cluster = reference_prep.obs.index.values\n",
    "\n",
    "base_dictionary = {}\n",
    "for i in np.unique(celltype_cluster):\n",
    "    base_dictionary[i] = 0\n",
    "\n",
    "nneighbors = 10\n",
    "list_of_arrays = []\n",
    "reference_prep_epi = reference_prep[\n",
    "    reference_prep.obs[\"Class\"].isin(unchanging_type_keys)\n",
    "]\n",
    "spatial_points_epi = np.array(\n",
    "    [\n",
    "        reference_prep_epi.obsm[\"X_spatial\"][:, 0],\n",
    "        reference_prep_epi.obsm[\"X_spatial\"][:, 1],\n",
    "    ]\n",
    ").T\n",
    "spatial_points = np.array(\n",
    "    [reference_prep.obsm[\"X_spatial\"][:, 0], reference_prep.obsm[\"X_spatial\"][:, 1]]\n",
    ").T\n",
    "reference_prep_epi_arr = np.array(reference_prep_epi.X)\n",
    "\n",
    "tree = KDTree(spatial_points_epi)\n",
    "for i_bac in tqdm(range(len(celltype_cluster))):\n",
    "    current_cell = celltype_cluster[i_bac]\n",
    "    distances, neighbors = tree.query(spatial_points[i_bac], k=nneighbors)\n",
    "    neighbors = np.array(list(neighbors))\n",
    "    gene_array = np.array(\n",
    "        np.sum(reference_prep_epi_arr[neighbors, :], axis=0)\n",
    "    ).squeeze()\n",
    "    list_of_arrays.append(gene_array)\n",
    "\n",
    "X = pd.DataFrame(np.array(list_of_arrays)).astype(H.dtype)\n",
    "W = model.transform(X)\n",
    "\n",
    "topics_frame = pd.DataFrame(W)\n",
    "\n",
    "topics_frame.columns = [\"Topic \" + str(i + 1) for i in range(len(topics_frame.columns))]\n",
    "topics_frame.index = reference_prep.obs.index.tolist()\n",
    "\n",
    "\n",
    "def zscore(column):\n",
    "    return (column - column.mean()) / column.std()\n",
    "\n",
    "\n",
    "# Apply the z-score function to each column in the dataframe\n",
    "topics_frame = topics_frame.apply(zscore)\n",
    "reference_prep.obs = reference_prep.obs.merge(\n",
    "    topics_frame, left_index=True, right_index=True\n",
    ")\n",
    "reference_prep.obs[\"topic\"] = pd.Categorical(\n",
    "    (np.argmax(topics_frame.values, axis=1) + 1).astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_prep.write(\n",
    "    os.path.join(\n",
    "        \"/mnt/sata1/Analysis_Alex/timecourse_replicates/unrolling_meta\",\n",
    "        \"reference_prep_decomposition_model.h5ad\",\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
