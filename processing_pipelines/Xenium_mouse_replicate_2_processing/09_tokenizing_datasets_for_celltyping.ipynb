{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### We used Geneformer to inform our manual celltype annotation of the replicate data, and tell us which cells were Epithelial and Stromal classes for axes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/amonell/Geneformer\")\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Put the path to the reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "\n",
    "ad = sc.read(\n",
    "    \"/mnt/sata1/Analysis_Alex/timecourse_final/analysis/cleaned/final_celltyped_and_axes.h5ad\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(ad.var.index.tolist()).to_csv(\n",
    "    r\"/mnt/sata1/Analysis_Alex/Geneformer/adcsv.csv\", index=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Converting gene names to human homolog ensembl ids\n",
    "We provide the following file in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl = pd.read_csv(\n",
    "    \"gProfiler_hsapiens_9-18-2023_2-31-49 PM.csv\"\n",
    ").drop_duplicates(\"initial_alias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.var[\"ensembl_id\"] = [i for i in ensembl[\"converted_alias\"] if not pd.isna(i)][\n",
    "    : len(ad.var.index)\n",
    "]\n",
    "ad.var.index = ad.var.ensembl_id.tolist()\n",
    "ad.obs[\"n_counts\"] = np.array(np.sum(ad.X, axis=1)).flatten()\n",
    "ad.obs[\"organ_major\"] = \"SI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"/mnt/sata1/Analysis_Alex/Geneformer/loom_xenium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.write_loom(\"/mnt/sata1/Analysis_Alex/Geneformer/loom_xenium/ad.loom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.obs[\"input_ids\"] = [i for i in range(len(ad.obs.index.tolist()))]\n",
    "d = {}\n",
    "for i in ad.var.index.tolist():\n",
    "    d[i] = True\n",
    "import pickle\n",
    "\n",
    "with open(\"/mnt/sata1/Analysis_Alex/Geneformer/ids.pkl\", \"wb\") as w:\n",
    "    pickle.dump(d, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = TranscriptomeTokenizer(\n",
    "    {\"Subtype\": \"cell_type\", \"organ_major\": \"organ_major\"}, nproc=4\n",
    ")\n",
    "tk.tokenize_data(\n",
    "    \"/mnt/sata1/Analysis_Alex/Geneformer/loom_xenium\",\n",
    "    \"/mnt/sata1/Analysis_Alex/Geneformer/loom_xenium/tokenized\",\n",
    "    \"train_xenium\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Tokenize datasets to annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "ensembl = pd.read_csv(\n",
    "    \"gProfiler_hsapiens_9-18-2023_2-31-49 PM.csv\"\n",
    ").drop_duplicates(\"initial_alias\")\n",
    "\n",
    "for filename in glob.glob(\"/mnt/sata1/Analysis_Alex/timecourse_replicates/day*\"):\n",
    "    outname = os.path.basename(filename)\n",
    "    try:\n",
    "        os.mkdir(\"/mnt/sata1/Analysis_Alex/Geneformer/loom_\" + outname)\n",
    "        ad = sc.read(\n",
    "            os.path.join(\n",
    "                \"/mnt/sata1/Analysis_Alex/timecourse_replicates\",\n",
    "                outname,\n",
    "                \"adatas/06_reference_mapped.h5ad\",\n",
    "            )\n",
    "        )\n",
    "        ad.var[\"ensembl_id\"] = [\n",
    "            i for i in ensembl[\"converted_alias\"] if not pd.isna(i)\n",
    "        ][: len(ad.var.index)]\n",
    "        ad.var.index = ad.var.ensembl_id.tolist()\n",
    "        ad.obs[\"n_counts\"] = np.array(np.sum(ad.X, axis=1)).flatten()\n",
    "        ad.obs[\"organ_major\"] = \"SI\"\n",
    "        ad.obs[\"Subtype\"] = 0\n",
    "        ad.write_loom(\n",
    "            \"/mnt/sata1/Analysis_Alex/Geneformer/loom_\"\n",
    "            + outname\n",
    "            + \"/\"\n",
    "            + outname\n",
    "            + \".loom\"\n",
    "        )\n",
    "\n",
    "        tk = TranscriptomeTokenizer(\n",
    "            {\"Subtype\": \"cell_type\", \"organ_major\": \"organ_major\"}, nproc=4\n",
    "        )\n",
    "        tk.tokenize_data(\n",
    "            \"/mnt/sata1/Analysis_Alex/Geneformer/loom_\" + outname,\n",
    "            \"/mnt/sata1/Analysis_Alex/Geneformer/loom_\" + outname + \"/tokenized\",\n",
    "            \"train_\" + outname,\n",
    "        )\n",
    "    except:\n",
    "        print(outname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
