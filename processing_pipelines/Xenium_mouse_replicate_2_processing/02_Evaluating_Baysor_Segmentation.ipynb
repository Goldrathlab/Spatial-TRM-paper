{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#### This code plots the processed Baysor segmentation over an FOV for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import glob\n",
    "import alphashape\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "from shapely.ops import transform\n",
    "from shapely.affinity import scale\n",
    "import imageio as io\n",
    "import tifffile as tiff\n",
    "import imagecodecs\n",
    "import shapely.affinity as sa\n",
    "import json\n",
    "from core_functions.segmentation_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"D:/amonell/timecourse_replicates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folders = glob.glob(os.path.join(data_dir, \"day*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "#### Plotting Segmentation on an FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "minx = 8000\n",
    "miny = 20000\n",
    "maxx = 10000\n",
    "maxy = 21000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in tqdm(input_folders):\n",
    "    print(input_file)\n",
    "    adata = sc.read(os.path.join(input_file, \"adatas\", \"01_preprocessed.h5ad\"))\n",
    "    xenium_output_path = os.path.join(input_file, \"xenium_output\")\n",
    "    baysor_transcripts = adata.uns[\"points\"]\n",
    "    print(\"Finished reading in adata and transcripts\")\n",
    "    pixel_size = get_pixel_size(xenium_output_path)\n",
    "    print(\"Subsetting FOV\")\n",
    "    transcript_subset_fov = subset_transcripts_file(\n",
    "        baysor_transcripts, pixel_size, minx, maxx, miny, maxy\n",
    "    )\n",
    "\n",
    "    img = import_image(xenium_output_path)\n",
    "\n",
    "    print(\"Making Shapes\")\n",
    "    shapes = (\n",
    "        transcript_subset_fov[\n",
    "            (transcript_subset_fov.split_cell != 0)\n",
    "            & (transcript_subset_fov.split_cell != -1)\n",
    "        ]\n",
    "        .groupby(\"split_cell\")[[\"x\", \"y\"]]\n",
    "        .apply(make_alphashape, alpha=0.05)\n",
    "    )\n",
    "    shapes = gpd.GeoSeries(shapes)\n",
    "\n",
    "    def scale_to_image(x, y):\n",
    "        return (x / pixel_size, y / pixel_size)\n",
    "\n",
    "    colors = sns.color_palette()[3]\n",
    "    shapes2 = shapes.apply(lambda x: transform(scale_to_image, x))\n",
    "\n",
    "    print(\"Plotting\")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "    img_cropped = img[minx:maxx, miny:maxy]\n",
    "    ax.imshow(img_cropped, vmax=np.percentile(img_cropped, 99.9))\n",
    "    # Create an empty GeoDataFrame to store adjusted polygons\n",
    "    adjusted_shapes = []\n",
    "\n",
    "    # Iterate through the shapes DataFrame and adjust each polygon\n",
    "    for original_polygon in shapes2:\n",
    "        scaled_polygon = sa.translate(original_polygon, -miny, -minx)\n",
    "        adjusted_shapes.append(scaled_polygon)\n",
    "\n",
    "    adjusted_shapes = gpd.GeoSeries(adjusted_shapes)\n",
    "\n",
    "    # Plot the adjusted polygons\n",
    "    adjusted_shapes.plot(facecolor=colors, edgecolor=\"none\", alpha=0.2, ax=ax)\n",
    "    adjusted_shapes.plot(facecolor=\"none\", edgecolor=colors, alpha=0.7, ax=ax)\n",
    "    ax.set_xlim((0, 1000))\n",
    "    # ax.set_ylim((1500, 500))\n",
    "    # plt.scatter((transcript_subset_fov.x.values/pixel_size) - miny, (transcript_subset_fov.y.values/pixel_size) - minx, s=1, linewidths=0.01, alpha=0.5, c='white')\n",
    "    try:\n",
    "        os.mkdir(os.path.join(input_file, \"figures\"))\n",
    "    except:\n",
    "        print(\"Figures dir already exists\")\n",
    "    try:\n",
    "        os.mkdir(os.path.join(input_file, \"figures\", \"Segmentation_Evaluation\"))\n",
    "    except:\n",
    "        print(\"Segmentation_Evaluation dir already exists\")\n",
    "    plt.savefig(\n",
    "        os.path.join(\n",
    "            input_file,\n",
    "            \"figures\",\n",
    "            \"Segmentation_Evaluation\",\n",
    "            \"baysor_refined_segmentation_fov_example.png\",\n",
    "        )\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Plotting a single FOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "minx = 24000\n",
    "miny = 20500\n",
    "maxx = 25000\n",
    "maxy = 21500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baysor_transcripts = adata.uns[\"points\"]\n",
    "print(\"Finished reading in adata and transcripts\")\n",
    "pixel_size = get_pixel_size(xenium_output_path)\n",
    "print(\"Subsetting FOV\")\n",
    "transcript_subset_fov = subset_transcripts_file(\n",
    "    baysor_transcripts, pixel_size, minx, maxx, miny, maxy\n",
    ")\n",
    "\n",
    "img = import_image(xenium_output_path)\n",
    "\n",
    "print(\"Making Shapes\")\n",
    "shapes = (\n",
    "    transcript_subset_fov[\n",
    "        (transcript_subset_fov.split_cell != 0)\n",
    "        & (transcript_subset_fov.split_cell != -1)\n",
    "    ]\n",
    "    .groupby(\"split_cell\")[[\"x\", \"y\"]]\n",
    "    .apply(make_alphashape, alpha=0.05)\n",
    ")\n",
    "shapes = gpd.GeoSeries(shapes)\n",
    "\n",
    "\n",
    "def scale_to_image(x, y):\n",
    "    return (x / pixel_size, y / pixel_size)\n",
    "\n",
    "\n",
    "colors = sns.color_palette()[3]\n",
    "shapes2 = shapes.apply(lambda x: transform(scale_to_image, x))\n",
    "\n",
    "print(\"Plotting\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
    "img_cropped = img[minx:maxx, miny:maxy]\n",
    "ax.imshow(img_cropped, vmax=np.percentile(img_cropped, 99.9))\n",
    "# Create an empty GeoDataFrame to store adjusted polygons\n",
    "adjusted_shapes = []\n",
    "\n",
    "# Iterate through the shapes DataFrame and adjust each polygon\n",
    "for original_polygon in shapes2:\n",
    "    scaled_polygon = sa.translate(original_polygon, -miny, -minx)\n",
    "    adjusted_shapes.append(scaled_polygon)\n",
    "\n",
    "adjusted_shapes = gpd.GeoSeries(adjusted_shapes)\n",
    "\n",
    "adjusted_shapes.plot(facecolor=colors, edgecolor=\"none\", alpha=0.2, ax=ax)\n",
    "adjusted_shapes.plot(facecolor=\"none\", edgecolor=colors, alpha=0.7, ax=ax)\n",
    "\n",
    "spots = transcript_subset_fov[\n",
    "    (transcript_subset_fov.split_cell != 0) & (transcript_subset_fov.split_cell != -1)\n",
    "].groupby(\"split_cell\")[[\"x\", \"y\"]]\n",
    "colors = np.random.rand(len(spots), 3)  # Generates random RGB colors\n",
    "\n",
    "# Create a scatter plot with random colors\n",
    "ct_col = 0\n",
    "# for spg in spots:\n",
    "#    ax.scatter(spg[1].x/pixel_size - miny, spg[1].y/pixel_size - minx, c=[colors[ct_col]], s=17)\n",
    "#    ct_col+=1\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(\n",
    "        input_file,\n",
    "        \"figures\",\n",
    "        \"Segmentation_Evaluation\",\n",
    "        \"baysor_refined_segmentation_fov_example.png\",\n",
    "    )\n",
    ")\n",
    "# ax.set_xlim((0, 1000))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
