{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from pyometiff import OMETIFFReader\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this notebook, we prepare H&E images for conversion in a Pix2pix GAN. We want to predict IF images from the H&E images so we can match them up with the Xenium output. \n",
    "Put in the path to the H&E file that you want to align as wll as the path to the corresponding experiment output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_HE_ome = '/projects/2023_Spatial_Paper/data/HE_timecourse/OMETIFF/d30_SI_r2.ome.tif'\n",
    "xenium_path = '/mnt/sata1/Analysis_Alex/timecourse_replicates/day30_SI_r2/xenium_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array_HE_orig = imageio.imread_v2(path_to_HE_ome)\n",
    "h_and_e  = img_array_HE_orig.astype(np.uint16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c047bcdea847049ccf4b0d3576886b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "image_chunks = []\n",
    "for row in tqdm(range(256, np.shape(h_and_e)[0]+256, 256)):\n",
    "    for col in range(256, np.shape(h_and_e)[1]+256, 256):\n",
    "        right_part = h_and_e[row - 256:row, col - 256:col, :]\n",
    "        left_part = h_and_e[row - 256:row, col - 256:col, :]\n",
    "        image_chunks.append(np.hstack([left_part, right_part]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert images with gan\n",
    "To convert images with the Pix 2 pix gan, remove all the files from the pix2pix test directory. Next, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, arr in enumerate(image_chunks):\n",
    "    # Convert the numpy array to an image\n",
    "    img = Image.fromarray(arr.astype('uint8'))\n",
    "\n",
    "    # Save the image to a file\n",
    "    img.save(os.path.join('/home/amonell/piloting/pytorch-CycleGAN-and-pix2pix/datasets/histology/test', f'image_{i + 1}.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above cell, go to the pix2pix directory, activate the pytorch conda environment and enter the command \n",
    "\n",
    "\n",
    "python test.py --dataroot ./datasets/histology --name histology_pix2pix --model pix2pix --direction BtoA\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
