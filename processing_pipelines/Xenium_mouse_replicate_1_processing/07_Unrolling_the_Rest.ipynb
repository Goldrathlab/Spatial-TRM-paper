{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "import glob\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from core_functions.unrolling import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Training model on reference. (Put in the reference dataset from script 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_path = \"D:/amonell/timecourse_final/day7_SI_DMSO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_topics = np.load(os.path.join(reference_path, \"unrolling\", \"base_topics.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"D:/amonell/timecourse_final\"\n",
    "path_adata = [\n",
    "    i\n",
    "    for i in glob.glob(os.path.join(data_dir, \"day*\"))\n",
    "    if os.path.basename(i) == os.path.basename(reference_path)\n",
    "][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Prepare Reference Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(os.path.join(path_adata, \"adatas\", \"05_reference_unrolled.h5ad\"))\n",
    "all_spatial = adata.obsm[\"X_spatial\"]\n",
    "\n",
    "try:\n",
    "    adata.X = adata.X.A\n",
    "except:\n",
    "    print(\"Adata already in array format\")\n",
    "\n",
    "topics_contain = base_topics\n",
    "spatial_points = np.array(\n",
    "    adata[adata.obs[\"topic\"].isin(topics_contain), :].obsm[\"X_spatial\"]\n",
    ")\n",
    "other_spatial = np.array(\n",
    "    adata[~adata.obs[\"topic\"].isin(topics_contain), :].obsm[\"X_spatial\"]\n",
    ")\n",
    "\n",
    "spatial_points = remove_outliers(spatial_points, 99)\n",
    "\n",
    "downsize = 10\n",
    "base_image = create_base_image(spatial_points, other_spatial, downsize=downsize)\n",
    "\n",
    "file_path = os.path.join(path_adata, \"unrolling\", \"roll_image_before_model.png\")\n",
    "base_image.save(file_path)\n",
    "adata.uns[\"unrolling_downsize\"] = downsize\n",
    "adata.write(os.path.join(path_adata, \"adatas\", \"05_reference_unrolled.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "##### Label the reference image. We have provided the labels we used in the ./labels/unrolling/reference folder. \n",
    "Parse Reference Image Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_num_points = 100000\n",
    "json_file_path = os.path.join(path_adata, \"unrolling\", \"roll_image_before_model.json\")\n",
    "removals, points, top_points, mid_points = extract_json_info(json_file_path)\n",
    "dont_remove, index_set = get_removal_indices(adata, removals, all_spatial)\n",
    "(\n",
    "    x_points_bottom,\n",
    "    y_points_bottom,\n",
    "    x_points_mid,\n",
    "    y_points_mid,\n",
    "    x_points_top,\n",
    "    y_points_top,\n",
    ") = identify_spiral(adata, points, top_points, mid_points, base_num_points)\n",
    "(\n",
    "    all_points,\n",
    "    distances_top,\n",
    "    indices_top,\n",
    "    distances_bottom,\n",
    "    indices_bottom,\n",
    "    distances_mid,\n",
    "    indices_mid,\n",
    ") = get_distances_and_indices(\n",
    "    adata,\n",
    "    dont_remove,\n",
    "    x_points_bottom,\n",
    "    y_points_bottom,\n",
    "    x_points_mid,\n",
    "    y_points_mid,\n",
    "    x_points_top,\n",
    "    y_points_top,\n",
    "    base_num_points,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Get Ready to train neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "##### Prepare Training Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_presorted = (\n",
    "    sc.read(os.path.join(path_adata, \"adatas\", \"04_tissue_cleared.h5ad\"))\n",
    "    .obs[\"topic\"]\n",
    "    .values[dont_remove]\n",
    ")\n",
    "model_input = np.array(\n",
    "    [\n",
    "        stats.zscore(distances_top),\n",
    "        stats.zscore(distances_mid),\n",
    "        stats.zscore(distances_bottom),\n",
    "        indices_top,\n",
    "        indices_mid,\n",
    "        indices_bottom,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "##### Prepare Training Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "axis = adata.obs[\"longitudinal\"].values[dont_remove]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "##### Define and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_continuous_features = np.shape(model_input)[0]  # Number of continuous features\n",
    "unique_categories = np.unique(topic_presorted)\n",
    "embedding_dim = 3  # Dimensionality of the embedding space\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Categorical data as a 1D array\n",
    "categorical_data = topic_presorted\n",
    "\n",
    "# One-hot encode the categorical data\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "categorical_data_encoded = encoder.fit_transform(categorical_data.reshape(-1, 1))\n",
    "\n",
    "# Define input for continuous data\n",
    "continuous_input = Input(shape=(num_continuous_features,), name=\"continuous_input\")\n",
    "\n",
    "# Define input for one-hot encoded categorical data\n",
    "categorical_input = Input(\n",
    "    shape=(categorical_data_encoded.shape[1],), name=\"categorical_input\"\n",
    ")\n",
    "\n",
    "# Concatenate the continuous and categorical inputs\n",
    "concatenated_inputs = Concatenate()([continuous_input, categorical_input])\n",
    "\n",
    "# Build the neural network architecture\n",
    "x = Dense(64, activation=\"relu\")(concatenated_inputs)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "output = Dense(1, activation=\"linear\", name=\"output\")(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=[continuous_input, categorical_input], outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"mean_squared_error\"\n",
    ")  # Use an appropriate loss function for your task\n",
    "\n",
    "continuous_data = model_input.T\n",
    "target_values = axis\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    {\n",
    "        \"continuous_input\": continuous_data,\n",
    "        \"categorical_input\": categorical_data_encoded,\n",
    "    },\n",
    "    y=target_values,\n",
    "    batch_size=batch_size,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "##### Use model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model for prediction on new data\n",
    "new_continuous_data = continuous_data\n",
    "new_categorical_data_encoded = categorical_data_encoded\n",
    "# predictions = model.predict({'continuous_input': new_continuous_data, 'categorical_input': new_categorical_data_encoded})\n",
    "predictions = model.predict(\n",
    "    {\n",
    "        \"continuous_input\": new_continuous_data,\n",
    "        \"categorical_input\": new_categorical_data_encoded,\n",
    "    }\n",
    ")\n",
    "adata.obs[\"predicted_longitudinal\"] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "##### Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(adata, basis=\"spatial\", color=\"predicted_longitudinal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Unrolling the rest of the swiss rolls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Put in the path to the experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"D:/amonell/timecourse_final\"\n",
    "input_folders = glob.glob(os.path.join(data_dir, \"day*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path_adata in input_folders:\n",
    "    adata = sc.read(os.path.join(path_adata, \"adatas\", \"04_tissue_cleared.h5ad\"))\n",
    "    all_spatial = adata.obsm[\"X_spatial\"]\n",
    "\n",
    "    try:\n",
    "        adata.X = adata.X.A\n",
    "    except:\n",
    "        print(\"Adata already in array format\")\n",
    "\n",
    "    topics_contain = base_topics\n",
    "    spatial_points = np.array(\n",
    "        adata[adata.obs[\"topic\"].isin(topics_contain), :].obsm[\"X_spatial\"]\n",
    "    )\n",
    "    other_spatial = np.array(\n",
    "        adata[~adata.obs[\"topic\"].isin(topics_contain), :].obsm[\"X_spatial\"]\n",
    "    )\n",
    "\n",
    "    spatial_points = remove_outliers(spatial_points, 99)\n",
    "\n",
    "    downsize = 10\n",
    "    base_image = create_base_image(spatial_points, other_spatial, downsize=downsize)\n",
    "\n",
    "    try:\n",
    "        os.mkdir(os.path.join(path_adata, \"unrolling\"))\n",
    "    except:\n",
    "        print(\"unrolling directory already exists\")\n",
    "    file_path = os.path.join(path_adata, \"unrolling\", \"roll_image.png\")\n",
    "    base_image.save(file_path)\n",
    "    adata.uns[\"unrolling_downsize\"] = downsize\n",
    "    adata.write(os.path.join(path_adata, \"adatas\", \"04_tissue_cleared.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Go to labelme (pip install labelme > labelme) > open > open roll_image.png > create polygons > make polygons and save. \n",
    "\n",
    "We have provided our labels in ./labels/unrolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path_adata in input_folders:\n",
    "    adata = sc.read(os.path.join(path_adata, \"adatas\", \"04_tissue_cleared.h5ad\"))\n",
    "    all_spatial = adata.obsm[\"X_spatial\"]\n",
    "    if os.path.basename(path_adata) == os.path.basename(reference_path):\n",
    "        json_file_path = os.path.join(\n",
    "            path_adata, \"unrolling\", \"roll_image_before_model.json\"\n",
    "        )\n",
    "    else:\n",
    "        json_file_path = os.path.join(path_adata, \"unrolling\", \"roll_image.json\")\n",
    "\n",
    "    base_num_points = 100000\n",
    "    removals, points, top_points, mid_points = extract_json_info(json_file_path)\n",
    "    dont_remove, index_set = get_removal_indices(adata, removals, all_spatial)\n",
    "    (\n",
    "        x_points_bottom,\n",
    "        y_points_bottom,\n",
    "        x_points_mid,\n",
    "        y_points_mid,\n",
    "        x_points_top,\n",
    "        y_points_top,\n",
    "    ) = identify_spiral(adata, points, top_points, mid_points, base_num_points)\n",
    "    (\n",
    "        all_points,\n",
    "        distances_top,\n",
    "        indices_top,\n",
    "        distances_bottom,\n",
    "        indices_bottom,\n",
    "        distances_mid,\n",
    "        indices_mid,\n",
    "    ) = get_distances_and_indices(\n",
    "        adata,\n",
    "        dont_remove,\n",
    "        x_points_bottom,\n",
    "        y_points_bottom,\n",
    "        x_points_mid,\n",
    "        y_points_mid,\n",
    "        x_points_top,\n",
    "        y_points_top,\n",
    "        base_num_points,\n",
    "    )\n",
    "\n",
    "    topic_presorted = adata.obs[\"topic\"].values[dont_remove]\n",
    "    model_input = np.array(\n",
    "        [\n",
    "            stats.zscore(distances_top),\n",
    "            stats.zscore(distances_mid),\n",
    "            stats.zscore(distances_bottom),\n",
    "            indices_top,\n",
    "            indices_mid,\n",
    "            indices_bottom,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Categorical data as a 1D array\n",
    "    categorical_data = topic_presorted\n",
    "\n",
    "    categorical_data_encoded = encoder.transform(categorical_data.reshape(-1, 1))\n",
    "\n",
    "    continuous_data = model_input.T\n",
    "\n",
    "    predictions = model.predict(\n",
    "        {\n",
    "            \"continuous_input\": continuous_data,\n",
    "            \"categorical_input\": categorical_data_encoded,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    new_longitidunal = np.zeros(len(adata.obs.index))\n",
    "    new_longitidunal[dont_remove] = predictions.flatten()\n",
    "    new_longitidunal[list(index_set)] = -1\n",
    "    adata.obs[\"predicted_longitudinal\"] = new_longitidunal\n",
    "    sc.pl.embedding(adata, basis=\"spatial\", color=\"predicted_longitudinal\")\n",
    "\n",
    "    adata.obs[\"not_removed_from_longitudinal\"] = new_longitidunal != -1\n",
    "    adata.write(os.path.join(path_adata, \"adatas\", \"05_unrolled.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.set_figure_params(dpi=300)\n",
    "for path_adata in input_folders:\n",
    "    adata = sc.read(os.path.join(path_adata, \"adatas\", \"05_unrolled.h5ad\"))\n",
    "    fig = sc.pl.embedding(\n",
    "        adata[adata.obs[\"not_removed_from_longitudinal\"], :],\n",
    "        basis=\"spatial\",\n",
    "        color=\"predicted_longitudinal\",\n",
    "        return_fig=True,\n",
    "        show=False,\n",
    "    )\n",
    "    try:\n",
    "        os.mkdir(os.path.join(path_adata, \"figures\", \"axes\"))\n",
    "    except:\n",
    "        print(\"axes directory already exists\")\n",
    "    fig.tight_layout()\n",
    "    plt.axis(\"equal\")\n",
    "    fig.savefig(os.path.join(path_adata, \"figures\", \"axes\", \"spatial_longitudinal.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
