{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook calculates spatial neighborhood decomposition across all of the MERSCOPE experiments. \n",
    "The purpose of this is to get several vectors that parameterize the niche of each cell for crypt-villus axis prediction. By using non negative matrix factorization on neighborhoods of epithelial and stromal cells, we capture recurrent neighborhood patterns that are conserved across space and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scanpy as sc\n",
    "import os\n",
    "from scipy.spatial import KDTree\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF\n",
    "from tqdm.notebook import tqdm\n",
    "from core_functions.neighborhood_decomposition import *\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the celltyped and clustered adata and put the paths to all of the individual SI adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = r'/projects/2023_Spatial_Paper/Analysis_Alex/merscope_final/analysis/final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folders = glob.glob('/projects/2023_Spatial_Paper/Analysis_Alex/merscope_final/SI*') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amonell/.local/lib/python3.10/site-packages/anndata/__init__.py:51: FutureWarning: `anndata.read` is deprecated, use `anndata.read_h5ad` instead. `ad.read` will be removed in mid 2024.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "combined_adata = sc.read(os.path.join(output_folder, 'full_celltypes_and_leiden.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit an NMF model on neighborhoods of gene expression within epithelial and stromal cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unchanging_type_keys = ['Epithelial', 'Stromal']\n",
    "combined_adata_no_immune = combined_adata[combined_adata.obs['Class'].isin(unchanging_type_keys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of neihgbors in each training neighborhood. \n",
    "nneighbors = 10\n",
    "dfs = []\n",
    "\n",
    "unique_batches = np.unique(combined_adata_no_immune.obs.new_batch.values)\n",
    "for input_file in input_folders:\n",
    "    for roll in ['roll1', 'roll2']:\n",
    "        adata = combined_adata_no_immune[combined_adata_no_immune.obs['batch'] == os.path.basename(input_file)+ f'_roll_{roll}']\n",
    "        adata_arr = np.array(adata.X)\n",
    "        celltype_cluster = adata.obs.index.values\n",
    "        list_of_arrays = []\n",
    "        spatial_points = np.array([adata.obsm['X_spatial'][:,0], adata.obsm['X_spatial'][:,1]]).T\n",
    "        tree = KDTree(spatial_points)\n",
    "        for i_bac in tqdm(range(len(celltype_cluster))):\n",
    "            current_cell = celltype_cluster[i_bac]\n",
    "            distances, neighbors = tree.query(spatial_points[i_bac], k=nneighbors)\n",
    "            neighbors = np.array(list(neighbors))\n",
    "            gene_array = np.array(np.sum(adata_arr[neighbors, :], axis=0)).squeeze()\n",
    "            list_of_arrays.append(gene_array)\n",
    "        \n",
    "        X = pd.DataFrame(np.array(list_of_arrays))\n",
    "        dfs.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amonell/mambaforge/envs/tensorflow/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/home/amonell/mambaforge/envs/tensorflow/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/amonell/mambaforge/envs/tensorflow/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/amonell/mambaforge/envs/tensorflow/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1665: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_arr = pd.concat(dfs)\n",
    "\n",
    "num_neighborhoods = 15\n",
    "X = X_arr\n",
    "f = len(X.columns)\n",
    "n = len(X.index.tolist())\n",
    "\n",
    "model = NMF(n_components=num_neighborhoods, random_state=0)\n",
    "W = model.fit_transform(X)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the NMF model to calculate neighborhood enrichment vectors across all of the MERSCOPE experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in input_folders:\n",
    "    for roll in ['roll1', 'roll2']:\n",
    "        adata = sc.read(os.path.join(input_file, 'adatas', f'05_unrolled_roll_{roll}.h5ad'))\n",
    "        \n",
    "        superclusters = combined_adata[combined_adata.obs['batch'] == os.path.basename(input_file)+ f'_roll_{roll}'].obs['Class'].values\n",
    "        cluster_observations = combined_adata[combined_adata.obs['batch'] == os.path.basename(input_file)+ f'_roll_{roll}'].obs[['leiden', 'Sub_leiden', 'Class', 'Type', 'Subtype', 'Immunocentric_Type']]\n",
    "        #cluster_observations.index = [i.split('-')[0] for i in cluster_observations.index.values]\n",
    "        adata.obs = adata.obs.merge(cluster_observations, left_on='cell', right_index=True, how='left')\n",
    "        celltype_cluster = adata.obs.index.values\n",
    "        base_dictionary = {}\n",
    "        for i in np.unique(celltype_cluster):\n",
    "            base_dictionary[i] = 0\n",
    "        nneighbors = 10\n",
    "        list_of_arrays = []\n",
    "        adata_epi = adata[adata.obs['Class'].isin(unchanging_type_keys)]\n",
    "        spatial_points_epi = np.array([adata_epi.obsm['X_spatial'][:,0], adata_epi.obsm['X_spatial'][:,1]]).T\n",
    "        spatial_points = np.array([adata.obsm['X_spatial'][:,0], adata.obsm['X_spatial'][:,1]]).T\n",
    "        adata_epi_arr = np.array(adata_epi.X)\n",
    "        \n",
    "        tree = KDTree(spatial_points_epi)\n",
    "        for i_bac in tqdm(range(len(celltype_cluster))):\n",
    "            current_cell = celltype_cluster[i_bac]\n",
    "            distances, neighbors = tree.query(spatial_points[i_bac], k=nneighbors)\n",
    "            neighbors = np.array(list(neighbors))\n",
    "            gene_array = np.array(np.sum(adata_epi_arr[neighbors, :], axis=0)).squeeze()\n",
    "            list_of_arrays.append(gene_array)\n",
    "        \n",
    "        X = pd.DataFrame(np.array(list_of_arrays)).astype(H.dtype)\n",
    "        W = model.transform(X)\n",
    "        \n",
    "        topics_frame = pd.DataFrame(W)\n",
    "        \n",
    "        topics_frame.columns = ['Topic '+str(i+1) for i in range(len(topics_frame.columns))]\n",
    "        topics_frame.index = adata.obs.index.tolist()\n",
    "        def zscore(column):\n",
    "            return (column - column.mean()) / column.std()\n",
    "        \n",
    "        # Apply the z-score function to each column in the dataframe\n",
    "        topics_frame = topics_frame.apply(zscore)\n",
    "        adata.obs=adata.obs.merge(topics_frame, left_index=True, right_index=True)\n",
    "        adata.obs['topic'] = pd.Categorical((np.argmax(topics_frame.values, axis = 1)+1).astype(str))\n",
    "\n",
    "        sc.set_figure_params(dpi=300)\n",
    "        figure = sc.pl.embedding(adata, basis='spatial', color='topic', vmax=1, cmap='Blues', title='Neighborhood', size=2, show=False, return_fig=True)\n",
    "        try:\n",
    "            os.mkdir(os.path.join(input_file,'figures', 'neighborhoods'))\n",
    "        except:\n",
    "            print('Figures/neighborhoods already made.')\n",
    "        figure.tight_layout()\n",
    "        plt.axis('equal')\n",
    "        figure.savefig(os.path.join(input_file,'figures', 'neighborhoods', f'neighborhoods_{roll}.png'))\n",
    "        plt.close()\n",
    "        adata.write(os.path.join(input_file, 'adatas', f'06_before_decomposition_model_{roll}.h5ad'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
