{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e85e866",
   "metadata": {},
   "source": [
    "### Postprocessing the Baysor segmentations\n",
    "##### Baysor has many instances where a cell does not overlap with a nucleus, or a cell contains multiple nuclei. This script seeks to correct that. We are very confident in our nuclei segmentations, and therefore are able to make these adjustments with confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cf849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import glob\n",
    "import alphashape\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "from shapely.ops import transform\n",
    "import imageio as io\n",
    "from core_functions.baysor_postprocessing import *\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea17f0",
   "metadata": {},
   "source": [
    "##### Put the path to the folders where the Baysor runs are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a152ea5e-012e-48a6-8386-69dd4b716c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'D:/amonell/merscope_final'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c858a-7f9a-4069-8311-514b289448b9",
   "metadata": {},
   "source": [
    "##### Create anndatas from processing Baysor Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d04d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folders = glob.glob(os.path.join(data_dir, 'SI*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c904678-57b4-4f8e-991c-59fa3923df26",
   "metadata": {},
   "source": [
    "#### To run without multithreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d9db62c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e1004a35804f328cfdfa7ac21e9941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "for input_file in tqdm(input_folders):\n",
    "    try: \n",
    "        os.mkdir(os.path.join(input_file, 'adatas'))\n",
    "    except:\n",
    "        print('Adatas dir already exists')\n",
    "    adata = sc.read(os.path.join(input_file, 'anndata.h5ad'))\n",
    "    adata.write(os.path.join(input_file, 'adatas', '01_preprocessed.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a137aa-7975-4d92-bfda-fb48201e2d57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_input_folder(input_file):\n",
    "    print(input_file)\n",
    "    try: \n",
    "        os.mkdir(os.path.join(input_file, 'adatas'))\n",
    "    except:\n",
    "        print('Adatas dir already exists')\n",
    "\n",
    "    transcripts, transcripts_cellpose = prepare_transcripts(input_file)\n",
    "    \n",
    "    result = assign_nuclei_to_cells(transcripts, transcripts_cellpose)\n",
    "\n",
    "    transcripts_with_gt_and_main_nucleus_filtered,  groupby_most_common_nucleus = find_main_nucleus(transcripts, transcripts_cellpose, result)\n",
    "\n",
    "    transcripts_with_gt_and_main_nucleus_filtered = reassign_multiple_nuclei(transcripts_with_gt_and_main_nucleus_filtered, groupby_most_common_nucleus)\n",
    "\n",
    "    anndata = make_adata(transcripts_with_gt_and_main_nucleus_filtered)\n",
    "    \n",
    "    anndata.write(os.path.join(input_file, 'adatas', '01_preprocessed.h5ad'))\n",
    "with ThreadPoolExecutor(max_workers=16) as executor:  # You can adjust max_workers as needed\n",
    "    list(tqdm(executor.map(process_input_folder, input_folders), total=len(input_folders)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
