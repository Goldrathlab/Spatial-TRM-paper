{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This script provides the framework used for doing a villus segmentation on a MERSCOPE experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio as io\n",
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 4902390226"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Path to the MERSCOPE output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merscope_path = \"D:/amonell/merscope_final/SI-Ctrl-L-RAR-R-dist-1-VS120-NP_Beta8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if_channel_cell_boundary = io.imread(\n",
    "    os.path.join(merscope_path, f\"images\", \"mosaic_PolyT_z3.tif\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downsizing and visualization of the PolyT staining from the MERSCOPE output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "downsize_factor = 5\n",
    "pad_height = (\n",
    "    downsize_factor - if_channel_cell_boundary.shape[0] % downsize_factor\n",
    ") % downsize_factor\n",
    "pad_width = (\n",
    "    downsize_factor - if_channel_cell_boundary.shape[1] % downsize_factor\n",
    ") % downsize_factor\n",
    "\n",
    "# Pad the array with zeros\n",
    "padded_array = np.pad(\n",
    "    if_channel_cell_boundary, ((0, pad_height), (0, pad_width)), mode=\"constant\"\n",
    ")\n",
    "\n",
    "new_width = int(padded_array.shape[1] / downsize_factor)\n",
    "new_height = int(padded_array.shape[0] / downsize_factor)\n",
    "\n",
    "image = cv2.resize(padded_array.astype(np.float32), (new_width, new_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(os.path.join(merscope_path, \"villi_images\"))\n",
    "except:\n",
    "    print(\"Villi images directory already made\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chunking the images so that a model can be trained on subsections in Cellpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = (4000, 4000)\n",
    "\n",
    "for i in range(0, image.shape[1], int(chunk_size[1] / 2)):\n",
    "    for j in range(0, image.shape[0], int(chunk_size[0] / 2)):\n",
    "        # Define the coordinates for cropping\n",
    "        left = i\n",
    "        upper = j\n",
    "        right = i + chunk_size[1]\n",
    "        lower = j + chunk_size[0]\n",
    "\n",
    "        # Crop the image chunk\n",
    "        chunk = image[upper:lower, left:right]\n",
    "\n",
    "        cv2.imwrite(\n",
    "            os.path.join(merscope_path, \"villi_images\", f\"chunk_{i}_{j}.png\"),\n",
    "            ((chunk / np.max(chunk)) * 255).astype(int),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running Cellpose on the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellpose_model_path = r\"D:/amonell/merscope_final/SI-Ctrl-L-RAR-R-dist-1-VS120-NP_Beta8/villi_images/models/CP_20231111_162456\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models\n",
    "from cellpose import io as cio\n",
    "\n",
    "model = models.CellposeModel(gpu=True, pretrained_model=cellpose_model_path)\n",
    "channels = [0, 0]\n",
    "masks_, flows_, styles_ = model.eval(\n",
    "    [((image / np.max(image)) * 255).astype(int)],\n",
    "    channels=channels,\n",
    "    diameter=392.78,\n",
    "    flow_threshold=0.4,\n",
    "    cellprob_threshold=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(merscope_path, \"villi_segmentation_mask.npy\"), masks_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\n",
    "    os.path.join(merscope_path, \"villi_segmentation_downsize_factor.npy\"),\n",
    "    np.array([downsize_factor]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks_[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timecourse_env_01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
