{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scanpy as sc\n",
    "import os\n",
    "from scipy.spatial import KDTree\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import NMF\n",
    "from tqdm.notebook import tqdm\n",
    "from core_functions.neighborhood_decomposition import *\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "We will use the Epithelial and Stromal classes defined by GeneFormer to perform a spatial decompostion on Epithelial and Stromal cells so that we have a feature set for crypt villus axis prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = r\"uninfected/analysis/cleaned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folders = glob.glob(\"uninfected/segmentation_SI*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "reading in the uninfected adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = []\n",
    "ct = 0\n",
    "for input_file in input_folders:\n",
    "    ada = sc.read(\n",
    "        os.path.join(input_file, \"adatas\", \"08_full_celltypes_and_leiden.h5ad\")\n",
    "    )\n",
    "    ada = ada[:, ~ada.var[\"gene\"].isna().values]\n",
    "    adatas.append(ada)\n",
    "    ct += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Path to the timecourse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_path = r\"timecourse.h5ad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Add the reference adata to the uninfected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only the reference data (the dataset with the best morphology that was treated as a reference for the first set of replicates)\n",
    "reference_adata = sc.read(reference_path)\n",
    "reference_adata = reference_adata[reference_adata.obs[\"batch\"] == \"day8_SI_Ctrl\"]\n",
    "\n",
    "adatas.append(reference_adata)\n",
    "combined_adata = sc.concat(adatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Train Decomposition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "unchanging_type_keys = [\"Epithelial\", \"Stromal\"]\n",
    "combined_adata_no_immune = combined_adata[\n",
    "    combined_adata.obs[\"Class\"].isin(unchanging_type_keys)\n",
    "]\n",
    "unique_batches = np.unique(combined_adata_no_immune.obs.batch.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "nneighbors = 10\n",
    "dfs = []\n",
    "for input_file in unique_batches:\n",
    "    adata = combined_adata_no_immune[\n",
    "        combined_adata_no_immune.obs[\"batch\"] == input_file\n",
    "    ]\n",
    "    adata_arr = np.array(adata.X.A)\n",
    "    celltype_cluster = adata.obs.index.values\n",
    "    list_of_arrays = []\n",
    "    spatial_points = np.array(\n",
    "        [adata.obsm[\"X_spatial\"][:, 0], adata.obsm[\"X_spatial\"][:, 1]]\n",
    "    ).T\n",
    "    tree = KDTree(spatial_points)\n",
    "    for i_bac in tqdm(range(len(celltype_cluster))):\n",
    "        current_cell = celltype_cluster[i_bac]\n",
    "        distances, neighbors = tree.query(spatial_points[i_bac], k=nneighbors)\n",
    "        neighbors = np.array(list(neighbors))\n",
    "        gene_array = np.array(np.sum(adata_arr[neighbors, :], axis=0)).squeeze()\n",
    "        list_of_arrays.append(gene_array)\n",
    "\n",
    "    X = pd.DataFrame(np.array(list_of_arrays))\n",
    "    dfs.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neighborhoods = 15\n",
    "X = X_arr\n",
    "del X_arr\n",
    "f = len(X.columns)\n",
    "n = len(X.index.tolist())\n",
    "\n",
    "model = NMF(n_components=num_neighborhoods, random_state=0)\n",
    "W = model.fit_transform(X)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Apply decomposition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_file in input_folders:\n",
    "    adata = sc.read(\n",
    "        os.path.join(input_file, \"adatas\", \"08_full_celltypes_and_leiden.h5ad\")\n",
    "    )\n",
    "\n",
    "    superclusters = adata.obs[\"Class\"].values\n",
    "    celltype_cluster = adata.obs.index.values\n",
    "\n",
    "    base_dictionary = {}\n",
    "    for i in np.unique(celltype_cluster):\n",
    "        base_dictionary[i] = 0\n",
    "\n",
    "    nneighbors = 10\n",
    "    list_of_arrays = []\n",
    "    adata_epi = adata[adata.obs[\"Class\"].isin(unchanging_type_keys)]\n",
    "    spatial_points_epi = np.array(\n",
    "        [adata_epi.obsm[\"X_spatial\"][:, 0], adata_epi.obsm[\"X_spatial\"][:, 1]]\n",
    "    ).T\n",
    "    spatial_points = np.array(\n",
    "        [adata.obsm[\"X_spatial\"][:, 0], adata.obsm[\"X_spatial\"][:, 1]]\n",
    "    ).T\n",
    "    adata_epi_arr = np.array(adata_epi.X.A)\n",
    "\n",
    "    tree = KDTree(spatial_points_epi)\n",
    "    for i_bac in tqdm(range(len(celltype_cluster))):\n",
    "        current_cell = celltype_cluster[i_bac]\n",
    "        distances, neighbors = tree.query(spatial_points[i_bac], k=nneighbors)\n",
    "        neighbors = np.array(list(neighbors))\n",
    "        gene_array = np.array(np.sum(adata_epi_arr[neighbors, :], axis=0)).squeeze()\n",
    "        list_of_arrays.append(gene_array)\n",
    "\n",
    "    X = pd.DataFrame(np.array(list_of_arrays)).astype(H.dtype)\n",
    "    X = X[X.columns[np.array(adata.var.index.isin(reference_adata.var.index))]]\n",
    "    W = model.transform(X)\n",
    "\n",
    "    topics_frame = pd.DataFrame(W)\n",
    "\n",
    "    topics_frame.columns = [\n",
    "        \"Topic \" + str(i + 1) for i in range(len(topics_frame.columns))\n",
    "    ]\n",
    "    topics_frame.index = adata.obs.index.tolist()\n",
    "\n",
    "    def zscore(column):\n",
    "        return (column - column.mean()) / column.std()\n",
    "\n",
    "    # Apply the z-score function to each column in the dataframe\n",
    "    topics_frame = topics_frame.apply(zscore)\n",
    "    adata.obs = adata.obs.merge(topics_frame, left_index=True, right_index=True)\n",
    "    adata.obs[\"topic\"] = pd.Categorical(\n",
    "        (np.argmax(topics_frame.values, axis=1) + 1).astype(str)\n",
    "    )\n",
    "\n",
    "    sc.set_figure_params(dpi=300)\n",
    "    figure = sc.pl.embedding(\n",
    "        adata,\n",
    "        basis=\"spatial\",\n",
    "        color=\"topic\",\n",
    "        vmax=1,\n",
    "        cmap=\"Blues\",\n",
    "        title=\"Neighborhood\",\n",
    "        size=2,\n",
    "        show=False,\n",
    "        return_fig=True,\n",
    "    )\n",
    "    try:\n",
    "        os.mkdir(os.path.join(input_file, \"figures\", \"neighborhoods\"))\n",
    "    except:\n",
    "        print(\"Figures/neighborhoods already made.\")\n",
    "    figure.tight_layout()\n",
    "    plt.axis(\"equal\")\n",
    "    figure.savefig(\n",
    "        os.path.join(input_file, \"figures\", \"neighborhoods\", \"neighborhoods.png\")\n",
    "    )\n",
    "    plt.close()\n",
    "    adata.write(\n",
    "        os.path.join(input_file, \"adatas\", \"09_before_decomposition_model.h5ad\")\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
