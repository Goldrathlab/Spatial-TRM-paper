{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download files\n",
    "\n",
    "This script will download the data required to reproduce the main figures.\n",
    "\n",
    "> In order to download the files, you will need the base-url that is provided with the submission of the manuscript. \n",
    ">\n",
    "> Once the paper is accepted, the files will be made publicly available. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "base_url = getpass.getpass(\"Please enter the base URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_and_extract_file(file: str, base_url: str, force: bool = False):\n",
    "    \"\"\"Downloads and extracts a file from a specified base URL.\n",
    "    Args:\n",
    "        file (str): Name of the file to download.\n",
    "        base_url (str): Base URL where the file is located.\n",
    "        force (bool, optional): If True, re-downloads the file even if\n",
    "                                it exists locally. Defaults to False.\n",
    "    Raises:\n",
    "        requests.exceptions.RequestException: If there is an error during download.\n",
    "        (OSError, ValueError): If there is an error during extraction.\n",
    "    \"\"\"\n",
    "    print(f\"Checking file {file}\")\n",
    "    # Ensure base_url ends with a slash\n",
    "    if not base_url.endswith(\"/\"):\n",
    "        base_url += \"/\"\n",
    "    full_url = f\"{base_url}{file}\"\n",
    "    basename = os.path.basename(file)\n",
    "    download_path = f\"{file}\"\n",
    "    if basename.endswith(\".gz\"):\n",
    "        download_path_extracted = download_path[:-3]\n",
    "    else:\n",
    "        download_path_extracted = download_path\n",
    "\n",
    "    # Check if file exists locally and compare sizes\n",
    "    local_file_exists = os.path.exists(download_path_extracted)\n",
    "    should_download = force\n",
    "\n",
    "    if local_file_exists and not force:\n",
    "        try:\n",
    "            # Get the size of the online file\n",
    "            response = requests.head(full_url)\n",
    "            response.raise_for_status()\n",
    "            online_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "            # Get the size of the local file\n",
    "            local_size = os.path.getsize(download_path_extracted)\n",
    "\n",
    "            if online_size != local_size:\n",
    "                print(\n",
    "                    f\"   Local file size ({local_size} bytes) differs from online file size ({online_size} bytes).\"\n",
    "                )\n",
    "                should_download = True\n",
    "            else:\n",
    "                print(f\"   File {file} is already downloaded and has the correct size.\")\n",
    "                return\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"   Error checking online file: {e}\")\n",
    "            return\n",
    "\n",
    "    if should_download:\n",
    "        if local_file_exists:\n",
    "            os.remove(download_path_extracted)\n",
    "            print(f\"      Removing existing file: {download_path_extracted}\")\n",
    "        print(f\"   Downloading file: {file}\")\n",
    "    else:\n",
    "        print(f\"   File {file} is already downloaded and up to date.\")\n",
    "        return\n",
    "\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(download_path), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        response = requests.get(full_url, stream=True)\n",
    "        response.raise_for_status()  # Raise an exception for error status codes\n",
    "        total_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "        with open(download_path, \"wb\") as f, tqdm(\n",
    "            desc=file,\n",
    "            total=total_size,\n",
    "            unit=\"iB\",\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as progress_bar:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                size = f.write(chunk)\n",
    "                progress_bar.update(size)\n",
    "\n",
    "        if basename.endswith(\".gz\"):\n",
    "            print(f\"Extracting {download_path}\")\n",
    "            with gzip.open(download_path, \"rb\") as f_in:\n",
    "                with open(download_path_extracted, \"wb\") as f_out:\n",
    "                    shutil.copyfileobj(f_in, f_out)\n",
    "            os.remove(download_path)  # Remove the compressed archive\n",
    "            print(f\"Extraction complete: {download_path_extracted}\")\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"   Error downloading file: {e}\")\n",
    "    except (OSError, ValueError) as e:\n",
    "        print(f\"   Error extracting file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"xenium_output/day8_r2/morphology_mip.ome.tif\",\n",
    "    \"xenium_output/day8_r2/experiment.xenium\",\n",
    "    \"xenium_output/human_09_r2/morphology_mip.ome.tif\",\n",
    "    \"xenium_output/human_09_r2/experiment.xenium\",\n",
    "    \"transcripts/transcripts_figure_5c.csv\",\n",
    "    \"images/day8_r2_h_and_e_alignment_gan.npy\",\n",
    "    \"images/human_09_r2_IF_alignment.npy\",\n",
    "    \"images/human_09_r2_h_and_e_alignment_gan.npy\",\n",
    "    \"images/day8_r2_IF_alignment.npy\",\n",
    "    \"adata/human.h5ad\",\n",
    "    \"adata/human_09_r2_with_transcripts.h5ad\",\n",
    "    \"adata/tgfb.h5ad\",\n",
    "    \"adata/day8_r2_with_transcripts.h5ad\",\n",
    "    \"adata/timecourse.h5ad\",\n",
    "    \"adata/uninfected.h5ad\",\n",
    "    \"adata/perturb.h5ad\",\n",
    "    \"adata/visium_hd.h5ad\",\n",
    "    \"IF/timecourse/day 120.txt\",\n",
    "    \"IF/timecourse/day 060.txt\",\n",
    "    \"IF/timecourse/day 006.txt\",\n",
    "    \"IF/timecourse/day 007.txt\",\n",
    "    \"IF/timecourse/day 005.txt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    download_and_extract_file(f, base_url, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
